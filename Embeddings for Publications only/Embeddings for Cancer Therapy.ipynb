{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.embedders import Word2Vec\n",
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.walkers import RandomWalker\n",
    "\n",
    "from rdflib import Graph\n",
    "import rdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the entities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data e.g. Data from 2022(The CSV is from Semopenalex SPARQL)\n",
    "data_work = pd.read_csv(\"Samples/work_2018.csv\", sep=\",\")\n",
    "\n",
    "#Define the entities from the CSV (here: All works & cited work on Cancer Therapy from 2022)\n",
    "entities = [entity for entity in data_work[\"work\"]]\n",
    "\n",
    "#Conect all entities\n",
    "entities_distinct = list(dict.fromkeys(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(entities_distinct))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the Knowledge Graph about the SPARQL-Endpoint\n",
    "The embeddings are calculated for the Works, but the goal is to represent the concepts. So the Literals are the Concept Titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph=KG(\n",
    "    \"https://semopenalex.org/sparql\",\n",
    "skip_predicates={\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"}, \n",
    "    literals=[\n",
    "        [\"https://semopenalex.org/property/hasConcept\",\n",
    "         \"http://www.w3.org/2004/02/skos/core#prefLabel\"]\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(knowledge_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the RDF2VecTransformer\n",
    " Embedder: Word2Vec (Standard)\n",
    " Walker: RandomWalker (Standard)\n",
    " Starts randomly at one node(entity) and then randomly moves to the neighbor node(other entities). These movements are recorded by the algorithm. For the algorithm there are these parameters:\n",
    "     - max_walks: Specifies how many paths are to be generated per node (entity)\n",
    "     - max_depth: Determines the maximum depth a random walker can reach while traversing the graph\n",
    "     - with_reverse: With True also reversed edges can be used, with False not\n",
    "     - n_jobs: Specifies many jobs (i.e. the number of paths that are generated simultaneously) to be controlled at the same time. The higher the value, the more processing power is required\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = RDF2VecTransformer(\n",
    "    Word2Vec(epochs=10),\n",
    "    walkers=[RandomWalker(max_walks=10, max_depth=4, with_reverse=False, n_jobs=2)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Calculate the Embeddings & create for each embedding the defined Literals\n",
    "embeddings, literals = transformer.fit_transform(knowledge_graph, entities_distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "literals"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform the embeddings from multiple dimensions to 2 dimensions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_tsne = TSNE(random_state=1).fit_transform(np.vstack(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data-Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The literals are given in a nested list. This is useless for the DataFrame, so the inner list is resolved"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "new_list = list(itertools.chain.from_iterable(literals))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a list with a tuple for each entity(work). The tuple contains for each entity(work) the concepts or the concept title"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, the concept titles and the 2-dimensional embeddings are stored together in a DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Concept Title\": new_list, \"X\":X_tsne[:,0], \"Y\":X_tsne[:,1]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tupel split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The problem now is that an entity (Work) has multiple concepts. For example Medicine, Internal medicine, ...\n",
    "The next step is to split the tuples with the concept titles so that each element of the tuple has a separate row in the DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_rows = []\n",
    "# Iteration over 'Concept Title'\n",
    "for i, tupel in enumerate(data['Concept Title']):\n",
    "    # Iteration over the elements of the tuple\n",
    "    for j in tupel:\n",
    "        # Add the elements, X and Y values to rows\n",
    "        data_rows.append({'Concept Title': j, 'X': data.at[i, 'X'], 'Y': data.at[i, 'Y']})\n",
    "\n",
    "#Create new DataFrame\n",
    "data_new = pd.DataFrame(data_rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculate the average"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "data_new now no longer contains any tuples, yet the concept titles are still contained multiple times in the DataFrame. Therefore, they are grouped in the next step and the average of each group is calculated.\n",
    "The average could be weighted if it is clear how often an entity (work) has been \"visited\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data_mean = data_new.groupby('Concept Title').mean()\n",
    "data_mean.reset_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set Cancer Therapy in Center"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The DataFrame looks good so far, but looking through the data, it is noticeable that Cancer Therapy is not in the center. The reason for this is that the algorithm does not know that we want to calculate the embeddings for Cancer Therapy. Therefore, the concept Cancer Therapy is now placed in the coordinate origin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "row_cancerTherapy = data_mean.loc[data_mean[\"Concept Title\"].isin(['Cancer therapy'])]\n",
    "row_index = row_cancerTherapy.index[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Read X and Y value\n",
    "x = data_mean.loc[row_index, 'X']\n",
    "y = data_mean.loc[row_index, 'Y']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Adjust X values of embeddings\n",
    "if x > 0:\n",
    "    for x_index, x_row in data_mean.iterrows():\n",
    "        data_mean.at[x_index, 'X'] = x_row['X'] - x\n",
    "elif x < 0:\n",
    "    for x_index, x_row in data_mean.iterrows():\n",
    "        data_mean.at[x_index, 'X'] = x_row['X'] + abs(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Adjust Y values of embeddings\n",
    "if y > 0:\n",
    "    for y_index, y_row in data_mean.iterrows():\n",
    "        data_mean.at[y_index, 'Y'] = y_row['Y'] - y\n",
    "elif y < 0:\n",
    "    for y_index, y_row in data_mean.iterrows():\n",
    "        data_mean.at[y_index, 'Y'] = y_row['Y'] + abs(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Removal of concepts that are not meaningful"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the embeddings are positioned correctly. However, there are empty fields, concept titles that consist only of \"a\" or \"b\".\n",
    "Because Semopenalex can only search for 3 or more characters, the filter was also set to 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "data_selected = data_mean[data_mean['Concept Title'].str.len() >=3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_selected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Removing concepts that are too large and irrelevant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the DataFrame, many major subject areas are included, such as medicine, biology, ... These concepts are not much use for the display, because they are very large and only over concepts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "big_concepts = ['Medicine', 'Biology', 'Internal medicine', 'Genetics', 'Cancer', 'Chemistry', 'Mathematics', 'Materials science', 'Algorithm', 'Computer science']\n",
    "data_selected = data_selected[~data_selected['Concept Title'].isin(big_concepts)].reset_index(drop=True)\n",
    "data_selected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2022 = data_selected.copy()\n",
    "data_2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Show the Top Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For visualization, it will be difficult to visualize over 1000 concepts in one chart, so the next function determines the top embeddings(the ones with the smallest distance to Cancer Therapy) and outputs them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_embeddings = 100\n",
    "data_2022['X_abs'] = data_2022['X'].abs()\n",
    "data_2022['Y_abs'] = data_2022['Y'].abs()\n",
    "data_2022['Abs_Gesamt'] = data_2022['X_abs'] + data_2022['Y_abs']\n",
    "data_2022 = data_2022.nsmallest(top_embeddings, 'Abs_Gesamt')\n",
    "data_2022.drop(['X_abs', 'Y_abs'], axis='columns', inplace=True)\n",
    "data_2022"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add the number of publications"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_countWork_2022 = pd.read_csv(\"Samples/2022/count_work_2022.csv\")\n",
    "data_countRelatedWork_2022 = pd.read_csv(\"Samples/2022/count_relatedWork_2022.csv\")\n",
    "data_count_2022 = data_countWork_2022.append(data_countRelatedWork_2022)\n",
    "data_count_2022 = data_count_2022.groupby('conceptTitle').sum()\n",
    "data_2022_merged = pd.merge(data_2022, data_count_2022, left_on='Concept Title', right_on='conceptTitle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_2022_merged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create RDF-File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the upload into the Metaphactory, the DataFrame has to be converted into an RDF file, for this we used the library rdflib\n",
    "- For the declaration of the namespace we used an example URI (\"http://example.com/\")\n",
    "- The definition of each concept is done in such a way that each concept (e.g. concept1) has been assigned:\n",
    "    1. the type Concept\n",
    "    2. the concept Title\n",
    "    3. x-coordinate\n",
    "    4. y-coordinate\n",
    "    5. distance, to sort\n",
    "    6. the year\n",
    "\n",
    "- !!! Attention, for the distinction in the metaphactory each predicate (e.g. namespace.title_2018) must be unique, therefore the year is appended behind it\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N2836aafbc24046ed87f482c51a45016a (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import XSD\n",
    "\n",
    "g = rdflib.Graph()\n",
    "namespace = rdflib.Namespace(\"http://example.com/\")\n",
    "for i, row in data_2022_merged.iterrows():\n",
    "    s = rdflib.URIRef(f\"http://example.com/concept{i}\")\n",
    "    g.add((s, rdflib.RDF.type, namespace.Concept))\n",
    "    g.add((s, namespace.title_2018_new, rdflib.Literal(row['Concept Title'])))\n",
    "    g.add((s, namespace.x_2018_new, rdflib.Literal(row['X'], datatype=XSD.float)))\n",
    "    g.add((s, namespace.y_2018_new, rdflib.Literal(row['Y'], datatype=XSD.float)))\n",
    "    g.add((s, namespace.distance_2018_new, rdflib.Literal(row['Abs_Gesamt'], datatype=XSD.float)))\n",
    "    g.add((s, namespace.worksCount_2018_new, rdflib.Literal(row['countWork'], datatype=XSD.integer)))\n",
    "    g.add((s, namespace.year_2018_new, rdflib.Literal(2018)))\n",
    "\n",
    "g.serialize(destination='Outcomes/embeddings_2018.ttl', format='turtle')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4eed0e4ac208b39471a32ccc3ec406fd0993f32776dcc38ecc96ca87d526a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
